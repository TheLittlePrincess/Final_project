{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"routes_with_zips_S3_and_github.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1DnLdr4U43hsbE_sbHa1A7Na49P2OFskw\n",
    "\"\"\"\n",
    "\n",
    "# replacing files on the drive for those on the S3\n",
    "# S3 link to be used:      s3://finalprojectaustintrash\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping, Point\n",
    "from rtree import Rtree\n",
    "import pygeos\n",
    "\n",
    "#read the routes file that contains one point per route\n",
    "routes = pd.read_csv(\"Routes_Tableau.csv\")\n",
    "\n",
    "routes.head()\n",
    "\n",
    "#routes to dataframe\n",
    "routes_df = gpd.GeoDataFrame(routes, geometry=gpd.points_from_xy(routes[\"Longitude (generated)\"], routes[\"Latitude (generated)\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# check file location and create base directory variable\n",
    "# base_dir will be a list with a single list item, but we need it to be a string\n",
    "# so we'll just grab the first index\n",
    "#base_dir = !pwd\n",
    "#!pwd\n",
    "#type(base_dir[0])\n",
    "\n",
    "# use base directory and filename to create the geopandas dataframe\n",
    "zips = gpd.read_file(f\"austin_area_zip_codes.csv\",GEOM_POSSIBLE_NAMES=\"the_geom\", KEEP_GEOM_COLUMNS=\"NO\")\n",
    "print(\"Zips:\")\n",
    "print(zips.head())\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "zips.geometry.plot(color=None, edgecolor='k',linewidth = 2,ax=ax)\n",
    "routes_df.geometry.plot(color='Orange', edgecolor='k',linewidth = 2,ax=ax)\n",
    "\n",
    "zip_coords = zips[['zipcode','geometry']]\n",
    "\n",
    "route_coords = routes_df[['Garb Rt','geometry']]\n",
    "\n",
    "zip_coords\n",
    "\n",
    "route_coords\n",
    "\n",
    "route_coords.dtypes\n",
    "\n",
    "# This cycles through all of the route coords and prints the coords with the zip code. Next step, change the print to a return, and then apply it to a new zip column in the route_df. \n",
    "#DICT TO CONTAIN POINT AND ZIP\n",
    "point_and_route = {\"point\":[], \"zip\":[]};\n",
    "for j in route_coords['geometry']:\n",
    "    idx = 0\n",
    "    found = 0\n",
    "    while (found == 0):\n",
    "        if Point(j).within(zip_coords['geometry'][idx]) or Point(j).intersects(zip_coords['geometry'][idx]):\n",
    "            point_and_route[\"point\"].append(str(j))\n",
    "            point_and_route[\"zip\"].append(str(zip_coords['zipcode'][idx]))\n",
    "            found = 1\n",
    "        else:\n",
    "            idx += 1\n",
    "\n",
    "route_coords[\"POINT\"] = point_and_route[\"point\"]\n",
    "\n",
    "route_coords[\"ZIP\"] = point_and_route[\"zip\"]\n",
    "\n",
    "route_coords\n",
    "\n",
    "# Import df_2017_routes (from waste_data_etl and on S3)\n",
    "df_2017_routes = pd.read_csv(\"routes_2017_weight.csv\")\n",
    "print(\"2017 Routes Dataframe\")\n",
    "print(df_2017_routes.head())\n",
    "\n",
    "#Merge route_cords and df_2017_routes (from waste_data_etl and on S3) on Garb Rt AND route_number to have the weight added to the first or the zip to the second\n",
    "\n",
    "# confirm there is only one zip code per route (there are multiple routes per zipcode)\n",
    "\n",
    "# list the routes per zip i.e for zip 78754 routes are PW41,PW32 and PW30 AND sum the weight per zipcode like groupby.(ZIP).su\n",
    "\n",
    "# Import full_zip_codes table\n",
    "df_full_zip_codes = pd.read_csv(\"full_zip_codes.csv\")\n",
    "print(\"DF Full Zip Codes\")\n",
    "print(df_full_zip_codes.head())\n",
    "\n",
    "# Add (merge or append?) the weight per zip code to the full_zip_codes table. AND the if possible add the list of routes per zipcode\n",
    "#df_zipcodes_housing_grb.head()\n",
    "\n",
    "#Drop na\n",
    "#df_zipcodes_housing_grb = df_zipcodes_housing_grb.dropna()\n",
    "#df_zipcodes_housing_grb.head()\n",
    "\n",
    "# Export final table the one to feed the model (full_zip_codes table PLUS weight and if possible routes)\n",
    "# Can we export it directly to S3?\n",
    "#df_zipcodes_housing_grb.to_csv(\"Austin_zipcodes_housing_grb.csv\")\n",
    "\n",
    "# This cycles through all of the route coords and prints the coords with the zip code. Next step, change the print to a return, and then apply it to a new zip column in the route_df. \n",
    "\n",
    "for j in route_coords['geometry']:\n",
    "  idx = 0 \n",
    "  found = 0\n",
    "  while (found == 0):\n",
    "    \n",
    "      if Point(j).within(zip_coords['geometry'][idx]) or Point(j).intersects(zip_coords['geometry'][idx]):\n",
    "        #print(\"Route coordinate \" + str(j) + \" is within \" + str(zip_coords['zipcode'][idx]))\n",
    "        found = 1\n",
    "      else:\n",
    "        idx += 1\n",
    "\n",
    "# We need this part because it needs to go through each polygon to check the route points\n",
    "  # for each row in zip_coords, is coord in that row's polygon?\n",
    "  #return current_row[\"zipcode\"]\n",
    "\n",
    "#def find_zipcode(row): \n",
    "#    try:\n",
    "#      coord = route_coord[\"geometry\"]\n",
    "#      # if find_within_zipcode returns something, return that value from this function\n",
    "#      # else, return null value\n",
    "#      if coord.within(zip_coords['geometry'][row.index]) or coord.intersects(zip_coords['geometry'][row.index]):\n",
    "#        return zip_coords[\"zipcode\"][row.index]\n",
    "#    except:\n",
    "#      return \"00000\"\n",
    "\n",
    "# This is to tinker with to see if we can get it to work.\n",
    "# idx = 0\n",
    "# for j in route_coords[\"geometry\"].values:\n",
    "#     try:\n",
    "#       if Point(j).within(zip_coords['geometry'][idx]) or Point(j).intersects(zip_coords['geometry'][idx]):\n",
    "#         routes_coords.append(j, zip_coords['zipcode'][idx])\n",
    "#     except:\n",
    "#       pass\n",
    "#     idx+=1\n",
    "\n",
    "#route_coords[\"zip\"] = route_coords.apply(\n",
    "#    lambda row: find_zipcode(row), axis=1)\n",
    "print(route_coords)\n",
    "\n",
    "#taken from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html#pandas.DataFrame.join\n",
    "#using example halfway down page with 'key_A' = 'Garb Rt' and 'key_B' = 'route_number', df_example = \"route_coords\" and df_other = \"df_2017_routes\"\n",
    "print(\"\\n\"*10 +\"Joined Dataframes\")\n",
    "df_routes_zips = route_coords.join(df_2017_routes.set_index('route_number'),on='Garb Rt')\n",
    "df_routes_zips= df_routes_zips[[\"Garb Rt\",\"ZIP\",\"load_weight\"]]\n",
    "print(df_routes_zips.head())\n",
    "df_full_zip_codes['ZIPCODE'] = df_full_zip_codes['ZIPCODE'].astype(str)\n",
    "df_routes_zips['ZIP'] = df_routes_zips['ZIP'].astype(str)\n",
    "df_routes_zips_demographics = df_routes_zips.join(df_full_zip_codes.set_index('ZIPCODE'),on='ZIP')\n",
    "print(\"\\n\"*10 +\"Joined Dataframes (routes - zips - demographics)\")\n",
    "print(df_routes_zips_demographics.sort_values(by=['ZIP']).head(15))\n",
    "#Using mean to perform group by without affecting median income, average income, total_housing units, etc\n",
    "df_zips_demographics = df_routes_zips_demographics.set_index(\"ZIP\").groupby(level=\"ZIP\").mean()\n",
    "#using sum to get the entire load weight in each zip code\n",
    "df_zips_demographics['load_weight'] = df_routes_zips_demographics.set_index(\"ZIP\").groupby(level=\"ZIP\").sum()['load_weight']\n",
    "print(df_zips_demographics.sort_values(by=['ZIP']).head(10))"
   ]
  }
 ]
}